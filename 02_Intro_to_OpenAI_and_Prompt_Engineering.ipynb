{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f4773c-7113-43ee-b85e-2b331d5ca475",
      "metadata": {
        "id": "28f4773c-7113-43ee-b85e-2b331d5ca475"
      },
      "outputs": [],
      "source": [
        "# %env NVIDIA_API_KEY=nvapi-1234567890abcdef   # replace with your API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bca158aa-1ac5-4278-9ef4-fe611f25aaaf",
      "metadata": {
        "tags": [],
        "id": "bca158aa-1ac5-4278-9ef4-fe611f25aaaf"
      },
      "outputs": [],
      "source": [
        "pip install -q python-dotenv openai langchain_nvidia_ai_endpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e237e25-de00-490d-bad2-fb3a4a352a22",
      "metadata": {
        "tags": [],
        "id": "2e237e25-de00-490d-bad2-fb3a4a352a22"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Get NVIDIA's API Key: the API key should start with \"nvapi-\"\n",
        "if not os.getenv(\"NVIDIA_API_KEY\"):\n",
        "    # load_dotenv(find_dotenv()) # read .env file\n",
        "    # apikey = os.getenv('NVIDIA_API_KEY')\n",
        "    from google.colab import userdata\n",
        "    apikey = userdata.get('NVIDIA_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "    api_key = apikey\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"meta/llama-3.1-8b-instruct\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Who found NVIDIA?\"}\n",
        "    ],\n",
        "    temperature=0.2,\n",
        "    max_tokens=400\n",
        ")\n",
        "# print(completion)\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "-RFccLv7LwPR"
      },
      "id": "-RFccLv7LwPR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion.choices[0].message"
      ],
      "metadata": {
        "id": "oSQlSBE2SMQz"
      },
      "id": "oSQlSBE2SMQz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama-3.1-8b-instruct\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "eNajl_fkVh5V"
      },
      "id": "eNajl_fkVh5V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Helper function"
      ],
      "metadata": {
        "id": "lB0DhoQoIxVc"
      },
      "id": "lB0DhoQoIxVc"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"meta/llama-3.1-8b-instruct\"):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "T3x1LBH3LwgO"
      },
      "id": "T3x1LBH3LwgO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_completion(\"What is a CPU?\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "CxGbg3DTLwiC"
      },
      "id": "CxGbg3DTLwiC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_completion(\"What is ChatGPT?\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "U1-NMBFNLwjy"
      },
      "id": "U1-NMBFNLwjy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create new Helper function"
      ],
      "metadata": {
        "id": "BH8AHQ8dzala"
      },
      "id": "BH8AHQ8dzala"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion_from_messages(messages, model=\"meta/llama3-8b-instruct\", temperature=0):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    # print(messages)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "messages =  [\n",
        "    {'role':'system', 'content':'You are friendly chatbot.'},\n",
        "    {'role':'user', 'content':'Hi, my name is David Attenborough'}  ]   # try to change name Joe Biden\n",
        "\n",
        "result = get_completion_from_messages(messages)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "njkuHLEkuNiV"
      },
      "id": "njkuHLEkuNiV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt template using LangChain"
      ],
      "metadata": {
        "id": "MTK2BcR9JK3d"
      },
      "id": "MTK2BcR9JK3d"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain_nvidia_ai_endpoints"
      ],
      "metadata": {
        "id": "dPSEFLBbKjUD"
      },
      "id": "dPSEFLBbKjUD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WHpxIgD-4oUx"
      },
      "id": "WHpxIgD-4oUx"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "\n",
        "chat = ChatNVIDIA(\n",
        "    model=\"meta/llama-3.1-8b-instruct\",\n",
        "    api_key = apikey,\n",
        "    temperature=0.0,\n",
        "    max_tokens=1024,\n",
        ")"
      ],
      "metadata": {
        "id": "kw3w8Osikmni"
      },
      "id": "kw3w8Osikmni",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Call simple chat"
      ],
      "metadata": {
        "id": "3GVdduEt1MOh"
      },
      "id": "3GVdduEt1MOh"
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke(\"How far can a seagull fly in one day? Tell me in 100 words\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "yNjVwT8d1JGA"
      },
      "id": "yNjVwT8d1JGA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke(\"ลาม่า (llama) มีถิ่นกำเนิดมาจากไหน?\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "moMc_CuD7FbU"
      },
      "id": "moMc_CuD7FbU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful AI bot. Your name is {name}\"),\n",
        "        (\"user\", \"I need your help to plan 5 days trip to {city}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | chat\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"name\": \"Jarvis\",\n",
        "        \"city\": \"San Francisco\",\n",
        "    }\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "id": "FpLx195MLw1c"
      },
      "id": "FpLx195MLw1c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "id": "b41ocAFb7JWA"
      },
      "id": "b41ocAFb7JWA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2nclMFze7Jb6"
      },
      "id": "2nclMFze7Jb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9AEGebPF7Jfq"
      },
      "id": "9AEGebPF7Jfq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLIDDZCw7JiY"
      },
      "id": "TLIDDZCw7JiY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f769NSjA7JzD"
      },
      "id": "f769NSjA7JzD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a884b7e-97b9-4ed5-a938-7e1edd54832e",
      "metadata": {
        "id": "8a884b7e-97b9-4ed5-a938-7e1edd54832e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Pytorch+NGC on Kubernetes Operator 240702161026",
      "language": "python",
      "name": "jupyter-eg-kernel-k8s-cmjkop-ngc-py-1i26n1a82"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}